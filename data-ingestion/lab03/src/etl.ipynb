{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-30T00:25:12.627525749Z",
     "start_time": "2023-08-30T00:25:12.569567380Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .master('local[*]')\n",
    "    .appName('ETL_LAB03')\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-30T00:25:12.818269477Z",
     "start_time": "2023-08-30T00:25:12.614137502Z"
    }
   },
   "outputs": [],
   "source": [
    "bank_df = spark.read.csv('../data/bronze/banks/EnquadramentoInicia_v2.tsv', header=True, sep='\\t')\n",
    "\n",
    "# Data Transformation for bank dataset\n",
    "for column in bank_df.columns:\n",
    "    bank_df = bank_df.withColumnRenamed(\n",
    "        existing=column, \n",
    "        new=column.lower()\n",
    "    )\n",
    "\n",
    "for replacement_action in [\n",
    "    (\"nome\", \"- PRUDENCIAL\", \"\"),\n",
    "    (\"nome\",\"(\\.+|\\/+|\\-+)\", \"\"),\n",
    "    (\"nome\",\" INSTITUIÇÃO DE PAGAMENTO\", \"\"),\n",
    "    (\"nome\",\"SOCIEDADE DE CRÉDITO, FINANCIAMENTO E INVESTIMENTO\", \"SCFI\"),\n",
    "    (\"nome\",\" SA\", \"\"),\n",
    "]:\n",
    "    bank_df = bank_df.withColumn(\n",
    "        \"nome\", regexp_replace(\n",
    "            replacement_action[0],\n",
    "            replacement_action[1],\n",
    "            replacement_action[2]\n",
    "        )\n",
    "    )\n",
    "bank_df = bank_df.withColumn('nome_fantasia', split(col('nome'),'  ').getItem(1))\n",
    "# print(bank_df.count())\n",
    "# bank_df = bank_df.na.drop()\n",
    "# bank_df = bank_df.dropDuplicates()\n",
    "# bank_df.show(5, truncate=False)\n",
    "# print(f\"Number of rows x columns - Bank Data: {bank_df.count()} x {len(bank_df.columns)}\")\n",
    "bank_df.write.mode(\"overwrite\").csv(\"../data/silver/banks\", header=True, sep=\";\")\n",
    "#bank_df.select('nome', 'nome_fantasia').distinct().orderBy('nome').show(100, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-30T00:25:13.307950995Z",
     "start_time": "2023-08-30T00:25:12.824237891Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/08/29 21:25:13 WARN CacheManager: Asked to cache already cached data.\n"
     ]
    }
   ],
   "source": [
    "# Lendo separado devido a estrutura diferente\n",
    "employee_df_1 = spark.read.format(\"csv\").option(\"header\", \"true\").option('delimiter','|').load(\"../data/bronze/employees/glassdoor_consolidado_join_match_less_v2.csv\")\n",
    "employee_df_2 = spark.read.format(\"csv\").option(\"header\", \"true\").option('delimiter','|').load(\"../data/bronze/employees/glassdoor_consolidado_join_match_v2.csv\")\n",
    "\n",
    "# Criando colunas\n",
    "employee_df_1 = employee_df_1.withColumn('Segmento', lit(''))\n",
    "employee_df_2 = employee_df_2.withColumn('CNPJ', lit(''))\n",
    "\n",
    "# Ordenando as colunas\n",
    "columns = [\"employer_name\", \"reviews_count\", \"culture_count\", \"salaries_count\", \"benefits_count\", \"employer-website\", \"employer-headquarters\", \"employer-founded\", \"employer-industry\", \"employer-revenue\", \"url\", \"Geral\", \"Cultura e valores\", \"Diversidade e inclusão\", \"Qualidade de vida\", \"Alta liderança\", \"Remuneração e benefícios\", \"Oportunidades de carreira\", \"Recomendam para outras pessoas(%)\", \"Perspectiva positiva da empresa(%)\", \"CNPJ\", \"Segmento\", \"Nome\", \"match_percent\"]\n",
    "\n",
    "employee_df_1 = employee_df_1.select(columns)\n",
    "employee_df_2 = employee_df_2.select(columns)\n",
    "\n",
    "# unindo os dados\n",
    "employee_df = employee_df_1.union(employee_df_2)\n",
    "\n",
    "# Data Transformation for employee dataset\n",
    "for column in employee_df.columns:\n",
    "    employee_df = employee_df.withColumnRenamed(\n",
    "        column, \n",
    "        column.replace(\"-\",\"_\").replace(\" \",\"_\").lower()\n",
    "    )\n",
    "\n",
    "employee_df.cache()\n",
    "\n",
    "for replacement_action in [\n",
    "    (\"nome\", \"- PRUDENCIAL\", \"\"),\n",
    "    (\"nome\",\"(\\.+|\\/+|\\-+)\", \"\"),\n",
    "    (\"nome\",\" INSTITUIÇÃO DE PAGAMENTO\", \"\"),\n",
    "    (\"nome\",\"SOCIEDADE DE CRÉDITO, FINANCIAMENTO E INVESTIMENTO\", \"SCFI\"),\n",
    "    (\"nome\",\" SA\", \"\"),\n",
    "]:\n",
    "    employee_df = employee_df.withColumn(\n",
    "        \"nome\", regexp_replace(\n",
    "            replacement_action[0],\n",
    "            replacement_action[1],\n",
    "            replacement_action[2]\n",
    "        )\n",
    "    )\n",
    "employee_df = employee_df.withColumn('employer_name', upper(col('employer_name')))\n",
    "\n",
    "# employee_df.select('nome','employer_name').distinct().orderBy('nome').show(100, truncate=False)\n",
    "#print(f\"Number of rows x columns - Employee Data: {employee_df.count()} x {len(employee_df.columns)}\")\n",
    "employee_df.write.mode(\"overwrite\").csv(\"../data/silver/employee\", header=True, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "outputs": [],
   "source": [
    "#Claims\n",
    "claims_df = spark.read.format(\"csv\").option(\"header\", \"true\").option('delimiter',',').load(\"../data/bronze/claims\")\n",
    "\n",
    "# Data Transformation for employee dataset\n",
    "for column in claims_df.columns:\n",
    "    claims_df = claims_df.withColumnRenamed(\n",
    "        column, \n",
    "        column.replace(\"-\",\"_\").replace(\" \",\"_\").lower()\n",
    "    )\n",
    "\n",
    "claims_df = claims_df.withColumnRenamed('cnpj_if', 'cnpj')\\\n",
    "    .withColumnRenamed('instituição_financeira', 'nome')\n",
    "\n",
    "for replacement_action in [\n",
    "    (\"nome\", \"- PRUDENCIAL\", \"\"),\n",
    "    (\"nome\",\"(\\.+|\\/+|\\-+)\", \"\"),\n",
    "    (\"nome\",\" \\(conglomerado\\)\", \"\"),\n",
    "    (\"nome\",\" INSTITUIÇÃO DE PAGAMENTO\", \"\"),\n",
    "    (\"nome\",\"SOCIEDADE DE CRÉDITO, FINANCIAMENTO E INVESTIMENTO\", \"SCFI\"),\n",
    "    (\"nome\",\" SA\", \"\"),\n",
    "]:\n",
    "    claims_df = claims_df.withColumn(\n",
    "        \"nome\", regexp_replace(\n",
    "            replacement_action[0],\n",
    "            replacement_action[1],\n",
    "            replacement_action[2]\n",
    "        )\n",
    "    )\n",
    "\n",
    "# claims_df = claims_df.na.drop()\n",
    "# claims_df = claims_df.dropDuplicates()\n",
    "# print(f\"Number of rows x columns - Employee Data: {employee_df.count()} x {len(employee_df.columns)}\")\n",
    "claims_df.write.mode(\"overwrite\").csv(\"../data/silver/claims\", header=True, sep=\";\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T00:25:32.681669309Z",
     "start_time": "2023-08-30T00:25:32.413605005Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "outputs": [],
   "source": [
    "# reading data for joining\n",
    "claims_df = spark.read.format(\"csv\").option(\"header\", \"true\").option('delimiter',';').load(\"../data/silver/claims\")\n",
    "employee_df = spark.read.format(\"csv\").option(\"header\", \"true\").option('delimiter',';').load(\"../data/silver/employee\")\n",
    "#employee_df = employee_df.drop('cnpj','segmento')\n",
    "banks_df = spark.read.format(\"csv\").option(\"header\", \"true\").option('delimiter',';').load(\"../data/silver/banks\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T00:25:33.981457247Z",
     "start_time": "2023-08-30T00:25:33.769454353Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "outputs": [],
   "source": [
    "banks_df = banks_df.alias('banks_df')\n",
    "claims_df = claims_df.alias('claims_df')\n",
    "join_df = claims_df.join(banks_df, 'nome', 'inner').select(col('banks_df.cnpj').alias('cnpj_banks'),'claims_df.*').drop('cnpj').withColumnRenamed('cnpj_banks','cnpj')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T00:25:34.187244411Z",
     "start_time": "2023-08-30T00:25:34.157992178Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "outputs": [],
   "source": [
    "employee_df = employee_df.alias('employee_df')\n",
    "join_df = join_df.alias('join_df')\n",
    "# tratando a coluna indice\n",
    "join_df.withColumn('índice', regexp_replace('índice', ',', '.'))\n",
    "\n",
    "# Unindo os dados\n",
    "join_df = join_df.join( employee_df, 'nome' , 'inner').select('join_df.nome',\n",
    "                                                              'join_df.cnpj',\n",
    "                                                              'join_df.categoria',\n",
    "                                                              'join_df.quantidade_total_de_clientes_–_ccs_e_scr',\n",
    "                                                              regexp_replace('join_df.índice', ',', '.').alias('índice'),\n",
    "                                                              'join_df.quantidade_total_de_reclamações',\n",
    "                                                              'employee_df.geral',\n",
    "                                                              'employee_df.remuneração_e_benefícios')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T00:25:34.711238948Z",
     "start_time": "2023-08-30T00:25:34.674137485Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "outputs": [],
   "source": [
    "# Estrutura final esperada:\n",
    "# Nome do Banco\n",
    "# CNPJ\n",
    "# Classificação do Banco\n",
    "# Quantidade de Clientes do Bancos\n",
    "# Índice de reclamações\n",
    "# Quantidade de reclamações\n",
    "# Índice de satisfação dos funcionários dos bancos\n",
    "# Índice de satisfação com salários dos funcionários dos bancos.\n",
    "\n",
    "final_df = join_df.select(col('nome').alias('Nome do Banco'), \n",
    "                           col('cnpj').alias('CNPJ'),\n",
    "                           col('categoria').alias('Classificação'),\n",
    "                           col('quantidade_total_de_clientes_–_ccs_e_scr').alias('Quantidade de Clientes do Bancos'),\n",
    "                           col('índice').cast('integer').alias('Índice de reclamações'),\n",
    "                           col('quantidade_total_de_reclamações').alias('Quantidade de reclamações'),\n",
    "                           col('geral').alias('Índice de satisfação dos funcionários dos bancos'),\n",
    "                           col('remuneração_e_benefícios').alias('Índice de satisfação com salários dos funcionários dos bancos'))\n",
    "\n",
    "final_df = final_df.groupBy('Nome do Banco',\n",
    "                            'CNPJ',\n",
    "                            'Classificação')\\\n",
    "                   .agg(round(avg('Quantidade de Clientes do Bancos')).alias('Quantidade de Clientes do Bancos'),\n",
    "                              avg('Índice de reclamações').alias('Índice de reclamações'),\n",
    "                              avg('Quantidade de reclamações').alias('Quantidade de reclamações'),\n",
    "                              avg('Índice de satisfação dos funcionários dos bancos').alias('Índice de satisfação dos funcionários dos bancos'),\n",
    "                              avg('Índice de satisfação com salários dos funcionários dos bancos').alias('Índice de satisfação com salários dos funcionários dos bancos'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T00:25:35.075858142Z",
     "start_time": "2023-08-30T00:25:35.019819922Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "outputs": [],
   "source": [
    "final_df.write.mode(\"overwrite\").csv(\"../data/gold/final_table\", header=True, sep=\";\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T00:25:44.324329302Z",
     "start_time": "2023-08-30T00:25:44.079134109Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
